{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d433712-3c2e-4fe2-880e-4ec18f8419f7",
   "metadata": {},
   "source": [
    "# Email Search AI – Generative Search System\n",
    "\n",
    "This notebook implements a robust generative search system for organizational email data.\n",
    "The system follows a three-layer architecture:\n",
    "1. Embedding Layer\n",
    "2. Search Layer\n",
    "3. Generation Layer\n",
    "\n",
    "The goal is to retrieve and summarize decisions, strategies, and timelines from large email corporates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356ed1a-64a9-46ad-9c3a-e838dc7ed02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "from typing import Dict\n",
    "\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9d361-691a-4291-9369-f5455992de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df = pd.read_csv(\"email_thread_details.csv\")\n",
    "emails_df = emails_df.dropna(subset=[\"body\"])\n",
    "\n",
    "print(\"Emails loaded:\", len(emails_df))\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac24d05-a5e4-46c5-b91c-8096d4514cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.read_csv(\"email_thread_summaries.csv\")\n",
    "print(\"Thread summaries loaded:\", len(summary_df))\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d77b2-5429-4e3f-a686-18a07e9d2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_email(text):\n",
    "    text = re.sub(r\"On .* wrote:\", \"\", text)\n",
    "    text = re.sub(r\"(From|Sent|To|Subject):.*\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "emails_df[\"clean_body\"] = emails_df[\"body\"].apply(clean_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6720e3-1627-46bb-856e-9b3e4e8dc142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_email(text, chunk_size=300, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(\" \".join(words[start:end]))\n",
    "        start += chunk_size - overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4946998-b187-444a-b98a-3b60b9ca8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, metadatas = [], []\n",
    "\n",
    "for _, row in emails_df.iterrows():\n",
    "    for i, chunk in enumerate(chunk_email(row[\"clean_body\"])):\n",
    "        documents.append(chunk)\n",
    "        metadatas.append({\n",
    "            \"thread_id\": row[\"thread_id\"],\n",
    "            \"subject\": row[\"subject\"],\n",
    "            \"timestamp\": row[\"timestamp\"],\n",
    "            \"from\": row[\"from\"],\n",
    "            \"to\": row[\"to\"],\n",
    "            \"doc_type\": \"email\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca570c0e-97db-42cf-a1d4-5ec420d07359",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "email_embeddings = embedding_model.encode(documents, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df043a3-e3e3-4543-b625-3f74a60424e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_docs = summary_df[\"summary\"].tolist()\n",
    "summary_metas = [{\"thread_id\": t, \"doc_type\": \"thread_summary\"} \n",
    "                 for t in summary_df[\"thread_id\"]]\n",
    "\n",
    "summary_embeddings = embedding_model.encode(summary_docs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e237c-a2ef-4415-a1fb-38d39330bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client(Settings(persist_directory=\"./email_db\"))\n",
    "\n",
    "collection = client.get_or_create_collection(\"email_search_ai\")\n",
    "\n",
    "collection.add(\n",
    "    documents=documents + summary_docs,\n",
    "    embeddings=list(email_embeddings) + list(summary_embeddings),\n",
    "    metadatas=metadatas + summary_metas,\n",
    "    ids=[f\"doc_{i}\" for i in range(len(documents) + len(summary_docs))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea24a6-f3fe-4bc6-abc1-9848b4876369",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache: Dict[str, tuple] = {}\n",
    "\n",
    "def cache_key(q): \n",
    "    return hashlib.md5(q.encode()).hexdigest()\n",
    "\n",
    "def search(query, top_k=10):\n",
    "    key = cache_key(query)\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "\n",
    "    emb = embedding_model.encode([query])[0]\n",
    "    results = collection.query(query_embeddings=[emb], n_results=top_k)\n",
    "    cache[key] = (results[\"documents\"][0], results[\"metadatas\"][0])\n",
    "    return cache[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f5f39-ebc8-4b54-87b5-538b98b89c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "def rerank(query, docs, metas, top_n=3):\n",
    "    scores = reranker.predict([(query, d) for d in docs])\n",
    "    ranked = sorted(zip(docs, metas, scores), key=lambda x: x[2], reverse=True)\n",
    "    return ranked[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908d31f-7f54-47a4-b92b-3103daf7e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def build_prompt(query, ranked):\n",
    "    summaries, emails = [], []\n",
    "    for doc, meta, _ in ranked:\n",
    "        if meta[\"doc_type\"] == \"thread_summary\":\n",
    "            summaries.append(doc)\n",
    "        else:\n",
    "            emails.append(f\"{meta['timestamp']} | {meta['from']} → {meta['to']}: {doc}\")\n",
    "\n",
    "    return f\"\"\"\n",
    "You are an enterprise email analysis assistant.\n",
    "\n",
    "THREAD SUMMARIES:\n",
    "{chr(10).join(summaries)}\n",
    "\n",
    "EMAIL EVIDENCE:\n",
    "{chr(10).join(emails)}\n",
    "\n",
    "QUESTION:\n",
    "{query}\n",
    "\n",
    "ANSWER (fact-based, concise):\n",
    "\"\"\"\n",
    "\n",
    "def generate_answer(query, ranked):\n",
    "    prompt = build_prompt(query, ranked)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba6276f-5f82-4eaa-b8a7-f897e1ea56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What decisions were made about Q3 marketing strategy?\",\n",
    "    \"Was budget approval discussed for Project Atlas?\",\n",
    "    \"What timelines were agreed upon for product launch?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b4204-a27e-4758-bacf-74ab20f1000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in queries:\n",
    "    docs, metas = search(q)\n",
    "    ranked = rerank(q, docs, metas)\n",
    "\n",
    "    print(\"\\nQUERY:\", q)\n",
    "    print(\"\\nTop 3 Search Results:\")\n",
    "    for i, (doc, meta, score) in enumerate(ranked, 1):\n",
    "        print(f\"[{i}] ({meta['doc_type']}) Score: {score:.2f}\")\n",
    "\n",
    "    print(\"\\nFinal Answer:\")\n",
    "    print(generate_answer(q, ranked))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
