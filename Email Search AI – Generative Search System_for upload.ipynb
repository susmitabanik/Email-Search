{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d433712-3c2e-4fe2-880e-4ec18f8419f7",
   "metadata": {},
   "source": [
    "# Email Search AI – Generative Search System\n",
    "\n",
    "This notebook implements a robust generative search system for organizational email data.\n",
    "The system follows a three-layer architecture:\n",
    "1. Embedding Layer\n",
    "2. Search Layer\n",
    "3. Generation Layer\n",
    "\n",
    "The goal is to retrieve and summarize decisions, strategies, and timelines from large email corporates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9356ed1a-64a9-46ad-9c3a-e838dc7ed02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Susmita Banik\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing standard Python libraries\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "from typing import Dict\n",
    "\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f9d361-691a-4291-9369-f5455992de67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails loaded: 21684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FW: Master Termination Log</td>\n",
       "      <td>2002-01-29 11:23:42</td>\n",
       "      <td>Gossett, Jeffrey C. JGOSSET</td>\n",
       "      <td>['Giron', 'Darron C. Dgiron', 'Love', 'Phillip...</td>\n",
       "      <td>\\n\\n -----Original Message-----\\nFrom: =09Ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FW: Master Termination Log</td>\n",
       "      <td>2002-01-31 12:50:00</td>\n",
       "      <td>Theriot, Kim S. KTHERIO</td>\n",
       "      <td>['Murphy', 'Melissa Mmurphy', 'Gossett', 'Jeff...</td>\n",
       "      <td>\\n\\n -----Original Message-----\\nFrom: =09Panu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>FW: Master Termination Log</td>\n",
       "      <td>2002-02-05 15:03:35</td>\n",
       "      <td>Theriot, Kim S. KTHERIO</td>\n",
       "      <td>['Murphy', 'Melissa Mmurphy', 'Anderson', 'Dia...</td>\n",
       "      <td>Note to Stephanie Panus....\\n\\nStephanie...ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>FW: Master Termination Log</td>\n",
       "      <td>2002-02-05 15:06:25</td>\n",
       "      <td>Theriot, Kim S. KTHERIO</td>\n",
       "      <td>['Hall', 'D. Todd Thall', 'Sweeney', 'Kevin Ks...</td>\n",
       "      <td>\\n\\n -----Original Message-----\\nFrom: =09Panu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>FW: Master Termination Log</td>\n",
       "      <td>2002-05-28 07:20:35</td>\n",
       "      <td>Kelly, Katherine L. KKELLY</td>\n",
       "      <td>['Germany', 'Chris Cgerman']</td>\n",
       "      <td>\\n\\n -----Original Message-----\\nFrom: =09McMi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thread_id                     subject            timestamp  \\\n",
       "0          1  FW: Master Termination Log  2002-01-29 11:23:42   \n",
       "1          1  FW: Master Termination Log  2002-01-31 12:50:00   \n",
       "2          1  FW: Master Termination Log  2002-02-05 15:03:35   \n",
       "3          1  FW: Master Termination Log  2002-02-05 15:06:25   \n",
       "4          1  FW: Master Termination Log  2002-05-28 07:20:35   \n",
       "\n",
       "                          from  \\\n",
       "0  Gossett, Jeffrey C. JGOSSET   \n",
       "1      Theriot, Kim S. KTHERIO   \n",
       "2      Theriot, Kim S. KTHERIO   \n",
       "3      Theriot, Kim S. KTHERIO   \n",
       "4   Kelly, Katherine L. KKELLY   \n",
       "\n",
       "                                                  to  \\\n",
       "0  ['Giron', 'Darron C. Dgiron', 'Love', 'Phillip...   \n",
       "1  ['Murphy', 'Melissa Mmurphy', 'Gossett', 'Jeff...   \n",
       "2  ['Murphy', 'Melissa Mmurphy', 'Anderson', 'Dia...   \n",
       "3  ['Hall', 'D. Todd Thall', 'Sweeney', 'Kevin Ks...   \n",
       "4                       ['Germany', 'Chris Cgerman']   \n",
       "\n",
       "                                                body  \n",
       "0  \\n\\n -----Original Message-----\\nFrom: =09Ther...  \n",
       "1  \\n\\n -----Original Message-----\\nFrom: =09Panu...  \n",
       "2  Note to Stephanie Panus....\\n\\nStephanie...ple...  \n",
       "3  \\n\\n -----Original Message-----\\nFrom: =09Panu...  \n",
       "4  \\n\\n -----Original Message-----\\nFrom: =09McMi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the email threads file\n",
    "emails_df = pd.read_csv(\"email_thread_details.csv\")\n",
    "emails_df = emails_df.dropna(subset=[\"body\"])\n",
    "\n",
    "print(\"Emails loaded:\", len(emails_df))\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac24d05-a5e4-46c5-b91c-8096d4514cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread summaries loaded: 4167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The email thread discusses the Master Terminat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A lunch meeting has been scheduled for May 5th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ben is updating a friend on his progress with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The recipient of the email thread initially ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The email thread discusses the long form confi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thread_id                                            summary\n",
       "0          1  The email thread discusses the Master Terminat...\n",
       "1          2  A lunch meeting has been scheduled for May 5th...\n",
       "2          3  Ben is updating a friend on his progress with ...\n",
       "3          4  The recipient of the email thread initially ex...\n",
       "4          5  The email thread discusses the long form confi..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading email summary file\n",
    "summary_df = pd.read_csv(\"email_thread_summaries.csv\")\n",
    "print(\"Thread summaries loaded:\", len(summary_df))\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a8d77b2-5429-4e3f-a686-18a07e9d2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans raw email text so it is suitable for embedding and semantic search\n",
    "def clean_email(text):\n",
    "    text = re.sub(r\"On .* wrote:\", \"\", text)\n",
    "    text = re.sub(r\"(From|Sent|To|Subject):.*\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "emails_df[\"clean_body\"] = emails_df[\"body\"].apply(clean_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e6720e3-1627-46bb-856e-9b3e4e8dc142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits a long email into smaller overlapping text chunks\n",
    "def chunk_email(text, chunk_size=300, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(\" \".join(words[start:end]))\n",
    "        start += chunk_size - overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4946998-b187-444a-b98a-3b60b9ca8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store text chunks and their metadata\n",
    "documents, metadatas = [], []\n",
    "\n",
    "# Iterate through each email row\n",
    "for _, row in emails_df.iterrows():\n",
    "\n",
    "    # Split the cleaned email body into overlapping chunks\n",
    "    for i, chunk in enumerate(chunk_email(row[\"clean_body\"])):\n",
    "\n",
    "        # Store the text chunk for embedding\n",
    "        documents.append(chunk)\n",
    "\n",
    "        # Store metadata associated with this chunk\n",
    "        metadatas.append({\n",
    "            \"thread_id\": row[\"thread_id\"],   # Conversation identifier\n",
    "            \"subject\": row[\"subject\"],       # Email subject\n",
    "            \"timestamp\": row[\"timestamp\"],   # Sent time\n",
    "            \"from\": row[\"from\"],             # Sender\n",
    "            \"to\": row[\"to\"],                 # Recipient(s)\n",
    "            \"doc_type\": \"email\"              # Used for filtering later\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca570c0e-97db-42cf-a1d4-5ec420d07359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de53316ab1f34102bcbb258f2c543ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1018 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a pre-trained sentence embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert each document chunk into a vector embedding\n",
    "email_embeddings = embedding_model.encode(\n",
    "    documents,\n",
    "    show_progress_bar=True  # Visual feedback during embedding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7df043a3-e3e3-4543-b625-3f74a60424e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5877a8c7ba2d4b0b84e9ae68759c1c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract summary text and prepare metadata\n",
    "summary_docs = summary_df[\"summary\"].tolist()\n",
    "summary_metas = [\n",
    "    {\"thread_id\": t, \"doc_type\": \"thread_summary\"}\n",
    "    for t in summary_df[\"thread_id\"]\n",
    "]\n",
    "\n",
    "# Generate embeddings for thread-level summaries\n",
    "summary_embeddings = embedding_model.encode(\n",
    "    summary_docs,\n",
    "    show_progress_bar=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88acdd7d-43cf-4aac-aa4c-260045f28dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add documents in smaller batches\n",
    "def batch_add(\n",
    "    collection,\n",
    "    documents,\n",
    "    embeddings,\n",
    "    metadatas,\n",
    "    ids,\n",
    "    batch_size=5000,  # safe batch size < Chroma max (~5461)\n",
    "):\n",
    "    \"\"\"\n",
    "    Add documents to ChromaDB in smaller batches to prevent InternalError.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(ids), batch_size):\n",
    "        collection.add(\n",
    "            documents=documents[i:i+batch_size],\n",
    "            embeddings=embeddings[i:i+batch_size],\n",
    "            metadatas=metadatas[i:i+batch_size],\n",
    "            ids=ids[i:i+batch_size],\n",
    "        )\n",
    "\n",
    "# Combine emails and summaries into single lists\n",
    "all_documents = documents + summary_docs\n",
    "all_embeddings = list(email_embeddings) + list(summary_embeddings)\n",
    "all_metadatas = metadatas + summary_metas\n",
    "all_ids = [f\"doc_{i}\" for i in range(len(all_documents))]\n",
    "\n",
    "# Add to Chroma in batches\n",
    "batch_add(\n",
    "    collection,\n",
    "    all_documents,\n",
    "    all_embeddings,\n",
    "    all_metadatas,\n",
    "    all_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5aea24a6-f3fe-4bc6-abc1-9848b4876369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple in-memory cache to avoid repeated vector searches\n",
    "cache: Dict[str, tuple] = {}\n",
    "\n",
    "def cache_key(q):\n",
    "    # Create a stable hash for each query string\n",
    "    return hashlib.md5(q.encode()).hexdigest()\n",
    "\n",
    "def search(query, top_k=10):\n",
    "    # Check cache first to avoid recomputing embeddings\n",
    "    key = cache_key(query)\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "\n",
    "    # Generate embedding for the query\n",
    "    emb = embedding_model.encode([query])[0]\n",
    "\n",
    "    # Perform vector similarity search in ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[emb],\n",
    "        n_results=top_k\n",
    "    )\n",
    "\n",
    "    # Cache and return documents with their metadata\n",
    "    cache[key] = (\n",
    "        results[\"documents\"][0],\n",
    "        results[\"metadatas\"][0]\n",
    "    )\n",
    "    return cache[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "892f5f39-ebc8-4b54-87b5-538b98b89c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a cross-encoder model for query-document relevance scoring\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "# Rerank retrieved documents based on their relevance to the query.\n",
    "def rerank(query, docs, metas, top_n=3):\n",
    "    # Predict relevance scores for each (query, document) pair\n",
    "    scores = reranker.predict([(query, d) for d in docs])\n",
    "\n",
    "    # Combine docs, metadata, and scores, then sort by score descending\n",
    "    ranked = sorted(\n",
    "        zip(docs, metas, scores),\n",
    "        key=lambda x: x[2],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    # Return only the top_n results\n",
    "    return ranked[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0908d31f-7f54-47a4-b92b-3103daf7e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client using the API key from environment variables\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='sk-something')  # key has been removed after running the code and before downl\n",
    "\n",
    "def build_prompt(query, ranked):\n",
    "    \"\"\"\n",
    "    Construct a structured prompt for the LLM using:\n",
    "    - Thread summaries (high-level context)\n",
    "    - Email chunks (evidence)\n",
    "    \"\"\"\n",
    "    summaries, emails = [], []\n",
    "\n",
    "    # Separate summaries from raw email chunks\n",
    "    for doc, meta, _ in ranked:\n",
    "        if meta[\"doc_type\"] == \"thread_summary\":\n",
    "            summaries.append(doc)  # Thread-level summary\n",
    "        else:\n",
    "            # Format email evidence with timestamp, sender, recipient, and content\n",
    "            emails.append(f\"{meta['timestamp']} | {meta['from']} → {meta['to']}: {doc}\")\n",
    "\n",
    "    # Combine everything into a single prompt\n",
    "    return f\"\"\"\n",
    "You are an enterprise email analysis assistant.\n",
    "\n",
    "THREAD SUMMARIES:\n",
    "{chr(10).join(summaries)}\n",
    "\n",
    "EMAIL EVIDENCE:\n",
    "{chr(10).join(emails)}\n",
    "\n",
    "QUESTION:\n",
    "{query}\n",
    "\n",
    "ANSWER (fact-based, concise):\n",
    "\"\"\"\n",
    "\n",
    "def generate_answer(query, ranked):\n",
    "    \"\"\"\n",
    "    Generate a fact-based answer from the LLM given:\n",
    "    - A user query\n",
    "    - Ranked documents (summaries + email chunks)\n",
    "    \"\"\"\n",
    "    # Build the prompt with relevant context\n",
    "    prompt = build_prompt(query, ranked)\n",
    "\n",
    "    # Call the OpenAI chat endpoint\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",               # Model choice\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],  \n",
    "        temperature=0                      # Deterministic / factual answers\n",
    "    )\n",
    "\n",
    "    # Return the assistant’s answer text\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bba6276f-5f82-4eaa-b8a7-f897e1ea56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What decisions were made about Q3 marketing strategy?\",\n",
    "    \"Was budget approval discussed for Project Atlas?\",\n",
    "    \"What timelines were agreed upon for product launch?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b6b4204-a27e-4758-bacf-74ab20f1000f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUERY: What decisions were made about Q3 marketing strategy?\n",
      "\n",
      "Top 3 Search Results:\n",
      "[1] (email) Score: -4.05\n",
      "[2] (email) Score: -5.25\n",
      "[3] (email) Score: -7.10\n",
      "\n",
      "Final Answer:\n",
      "The emails indicate that there was a discussion regarding the timing of income recognition, with Ben Jacoby seeking input on whether to close a deal as scheduled, which could impact Q2 and Q3. Additionally, Louise Kitchen expressed a preference for a focus on Q4 rather than Q3. However, no definitive decisions about the Q3 marketing strategy were made in the provided emails.\n",
      "\n",
      "QUERY: Was budget approval discussed for Project Atlas?\n",
      "\n",
      "Top 3 Search Results:\n",
      "[1] (thread_summary) Score: -4.20\n",
      "[2] (email) Score: -5.77\n",
      "[3] (email) Score: -6.03\n",
      "\n",
      "Final Answer:\n",
      "No, budget approval for Project Atlas was not specifically discussed in the email thread. The focus was on the proposal of using a statement of work template for approving major projects and the related budget items for IT projects.\n",
      "\n",
      "QUERY: What timelines were agreed upon for product launch?\n",
      "\n",
      "Top 3 Search Results:\n",
      "[1] (email) Score: -4.95\n",
      "[2] (email) Score: -4.96\n",
      "[3] (email) Score: -5.23\n",
      "\n",
      "Final Answer:\n",
      "The agreed timelines for the product launch are as follows:\n",
      "\n",
      "1. Final draft comments due by Friday, July 14, 2000.\n",
      "2. Circulate draft to customers and conduct customer meetings from Monday, July 17 to Wednesday, July 26, 2000.\n",
      "3. Final internal review/edit of filing on Thursday, July 27, 2000.\n",
      "4. FERC filing scheduled for Monday, July 31, 2000.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each query in the list\n",
    "for q in queries:\n",
    "    docs, metas = search(q)\n",
    "    ranked = rerank(q, docs, metas)\n",
    "    print(\"\\nQUERY:\", q)\n",
    "    print(\"\\nTop 3 Search Results:\")\n",
    "    for i, (doc, meta, score) in enumerate(ranked, 1):\n",
    "        print(f\"[{i}] ({meta['doc_type']}) Score: {score:.2f}\")\n",
    "    print(\"\\nFinal Answer:\")\n",
    "    print(generate_answer(q, ranked))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b7514-a95e-4fd7-b776-ee46c2f3063f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
